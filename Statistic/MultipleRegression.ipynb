{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FerminMendez/ModuleAI/blob/main/Statistic/MultipleRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TejnBn8gTopy"
      },
      "source": [
        "# 0 Importando los datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvolHWOF0Y8k"
      },
      "source": [
        "Primeramente importamos algunas de las librerias que vamos a usar. Principalmente enfocadas ala manejo de datos y gráficas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qN9jAwrLTbhN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIh7I1bf0k_i"
      },
      "source": [
        "Accedemos al path donde está el Data Set. En este caso tenemos información financiera de las empresas de EU a partir del año 2000;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQvef_3LaGyD"
      },
      "outputs": [],
      "source": [
        "drive.mount(\"/content/gdrive\")\n",
        "!pwd\n",
        "%cd \"/content/gdrive/MyDrive/DataSetIA/US_dataset\"\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvLbkTJXaN3S"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('dataus2023.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeA3eEEVav_K"
      },
      "outputs": [],
      "source": [
        "firms = pd.read_csv('firmsus2023.csv')\n",
        "firms.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Awp06MPHay_a"
      },
      "outputs": [],
      "source": [
        "firms_selected=firms[[\"empresa\",\"Nombre\",\"status\",\"naics1\"]]\n",
        "firms_selected.columns=['firm',\"Empresa\",\"status\",\"industria\"]\n",
        "data =firms_selected.merge(data, on='firm', how='left')\n",
        "data['qy'] = data['q'].str[:4]\n",
        "data['qn'] = data['q'].str[5]\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4Cyga6ReIwy"
      },
      "source": [
        "Como se puede ver tenemos dos DataSet que se relacionan. Con el fin de tener toda la información relevante en un dataset vamos a mezclar los dataframe de data y firms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWcfCZpkbauc"
      },
      "source": [
        "## 0.1 Tranformando los tipos de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQvJDjz3beSk"
      },
      "outputs": [],
      "source": [
        "data['qdate']=pd.PeriodIndex(data.q, freq='Q')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc_rj73pbshC"
      },
      "source": [
        "## 0.2 Más informacion relevante\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiwGjt-dbv9v"
      },
      "outputs": [],
      "source": [
        "data['ry']= np.log(data['adjprice']) - np.log(data.groupby(['firm'])['adjprice'].shift(4))\n",
        "data['rq']= np.log(data['adjprice']) - np.log(data.groupby(['firm'])['adjprice'].shift(1))\n",
        "# ebit = revenue - cogs - sgae\n",
        "data['ebit']=data['revenue'] - data['cogs'] - data['sgae']\n",
        "\n",
        "#opm = ebit / revenue\n",
        "# data['opm']=data['ebit']/ data['revenue'] -> Hay que hacer las validaciones de que el divisor sea distinton de 0\n",
        "data['opm']= np.where(data['revenue']==0,np.NaN, data['ebit']/ data['revenue'])\n",
        "# Calculate net income as: netincome = ebit + otherincome + extraordinaryitems - financial expenses - incometax\n",
        "data['netincome'] = data['ebit']+ data['otherincome'] +data['extraordinaryitems'] - data['finexp'] -data['incometax']\n",
        "\n",
        "#Calculate profit margin (ratio) as: pm = ni / revenue\n",
        "data['pm'] = np.where(data['revenue']==0,np.NaN, data['netincome']/ data['revenue'])\n",
        "\n",
        "#Calculate asset turn over ratio: ato = revenue / totalassets\n",
        "data['ato'] = np.where(data['totalassets']==0,np.NaN, data['revenue']/ data['totalassets'])\n",
        "\n",
        "#Calculate acid ratio: acidratio = currentassets / currentliabilities\n",
        "data['acidratio']= np.where(data['currentliabilities']==0,np.NaN, data['currentassets']/ data['currentliabilities'])\n",
        "\n",
        "#Calculate financial leverage ratio as: finlev=longdebt / totalassets\n",
        "data['finlev'] = np.where(data['totalassets']==0,np.NaN, data['longdebt']/ data['totalassets'])\n",
        "\n",
        "#Calculate market value as: mvalue = originalprice * sharesoutstanding\n",
        "data['mvalue']=data['originalprice']*data['sharesoutstanding']\n",
        "\n",
        "#Calculate book value as: bookvalue = totalassets - totalliabilities\n",
        "data['bookvalue'] = data['totalassets'] - data['totalliabilities']\n",
        "\n",
        "#Retornos futuros a 1 y 4 trimestres\n",
        "data['f1rq']= data.groupby(['firm'])['rq'].shift(-1)\n",
        "data['f4rq']= data.groupby(['firm'])['rq'].shift(-4)\n",
        "\n",
        "#Retornos futuros a 1 y 4 años\n",
        "data['f1ry']= data.groupby(['firm'])['ry'].shift(-1)\n",
        "data['f4ry']= data.groupby(['firm'])['ry'].shift(-4)\n",
        "\n",
        "#Separción del número de trimestre y año\n",
        "data['qy'] = data['q'].str[:4]\n",
        "data['qn'] = data['q'].str[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFUbqZ43pLc8"
      },
      "outputs": [],
      "source": [
        "#data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4KkC70tcGyt"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vhm2ewgR2ByO"
      },
      "source": [
        "Copia de los datasets y subdatasets que usaremos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykGtSot9eY2o"
      },
      "outputs": [],
      "source": [
        "#Dataframe general\n",
        "#data: Este dataset tiene TODA la información original de los datasets originales, además los cálculos financieros.\n",
        "data=data.copy()\n",
        "\n",
        "#Dataframe manofactura\n",
        "#df_m:  Filtro por indudria. Año cierre del año fiscal 2022\n",
        "df_m=data.copy()\n",
        "df_m=df_m[(df_m['fiscalmonth']==12) & (df_m['industria']==\"Industrias manufactureras\") ]\n",
        "\n",
        "\n",
        "#Dataframe manofactura año 2022\n",
        "df=data.copy()\n",
        "df=df[(df['fiscalmonth']==12) & (df['industria']==\"Industrias manufactureras\") & df['qy']=='2022']\n",
        "df_m_2022=df;\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzSTBJ5tndV7"
      },
      "source": [
        "#1 Estadistica avanzada\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dShKeI48nmXw"
      },
      "source": [
        "## 1.1 Analitica descriptiva\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5dv_t4bn5Mh"
      },
      "source": [
        "### Análisis de los ratios: Comparando media ,media y mediana.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7JDoxZ43vOm"
      },
      "outputs": [],
      "source": [
        "#df_m.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hmX54lG5XVV"
      },
      "source": [
        "Preparamos el dataset para trabajar con los ratios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpzRj-GKoFnI"
      },
      "outputs": [],
      "source": [
        "#Trabajamos con el dataset de manofactura\n",
        "df=df_m.copy()\n",
        "#Selección de las columnas que corresponden a un ratio, sus denominadores y numeradores\n",
        "ratios_columns=     ['opm'    ,'pm'        ,'ato'         ,'acidratio'         ,'finlev' ]\n",
        "numerators_columns= ['ebit'   ,'netincome' ,'revenue'     ,'currentassets'     ,'longdebt']\n",
        "denomintaor_columns=['revenue','revenue'   ,'totalassets' ,'currentliabilities','totalassets']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGOUjTHI5cPX"
      },
      "source": [
        "Con la ayuda de .decribe() vamos a encontrar la media y mediana de los ratios. Los pesos ponderados los calcularemos de manera manual y desplegaremos toda la información de los ratios en un mismo dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKVaeR_6oBiO"
      },
      "outputs": [],
      "source": [
        "df_stats=df[ratios_columns].describe().T[['mean','50%','std']].T\n",
        "weight_mean=np.zeros(len(ratios_columns), dtype = float)\n",
        "for i in range(len(ratios_columns)):\n",
        "  name=ratios_columns[i]\n",
        "  weight_mean[i]=df[numerators_columns[i]].sum()/df[denomintaor_columns[i]].sum()\n",
        "\n",
        "df_stats=df_stats.T\n",
        "df_stats['weight mean']=weight_mean\n",
        "print(df_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKZSpn-r6ajF"
      },
      "source": [
        "Hasta ahora hemos calculado la media, mediana y media ponderada de la industria manofacturera. ¿Qué medida es la más representativa?¿Qué podemos decir del profit margin y asset turn over de la industria manofaturera?\n",
        "\n",
        "La media es el mejor punto de referencia cuando tenemos una distribución de datos normales. En estos casos la media y mediana suelen ser muy parecidas. En este caso tenemos todo lo contrario. Una dispersión de datos muy grande, la deviación estandar se aleja mucho de lo limites y no podemos decir que alguna de estas medidas represente el comportamiento de la industria manofacturera en los últimos años.\n",
        "\n",
        "Cuando utilizamos **la media ponderada** estamos tratando a la industria manofacturera como una sola entidad, no busca describir el comportamiento de una empresa promedio o típica, describe el comportamiento del sector, **es la mejor medida de tendencia cuando tenemos empresas tan pequeñas o tan grandes**, de esta manera el peso de cada empresa corresponde al poder explicativo que tiene sobre el comportamiento del sector.\n",
        "\n",
        "**Profit Margin de la industria manofacturera**\n",
        "*   pm = 0.074770\n",
        "\n",
        "*Tenemos que de todos los ingresos de la industria manofacturera en los últimos 20 años se capitaliza el 7.4% de los ingresos como ganancias.*\n",
        "\n",
        "**Asset turn over de la industria manofacturera**\n",
        "\n",
        "*   ato = 0.743507\n",
        "\n",
        "*Tenemos que el ato es la capacidad de una empresa para convertir sus activos en ganancias. De acuerdo a esta información la industria manofacturera en un periodo de un año ha logrado transformar el 74% del valor de sus activos en ganancias en un año durante los útltimos 20 años.*\n",
        "\n",
        "**Con esto podemos decir que la industria manofacturera desde el año 2000 ha mostrado una buena salud financiera**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPkvlX11qzQN"
      },
      "outputs": [],
      "source": [
        "#Replicamos el proceso para el año 2022\n",
        "df=df_m_2022.copy()\n",
        "ratios_columns=     ['opm'    ,'pm'        ,'ato'         ,'acidratio'         ,'finlev' ]\n",
        "numerators_columns= ['ebit'   ,'netincome' ,'revenue'     ,'currentassets'     ,'longdebt']\n",
        "denomintaor_columns=['revenue','revenue'   ,'totalassets' ,'currentliabilities','totalassets']\n",
        "df_stats=df[ratios_columns].describe().T[['mean','50%','std']].T\n",
        "weight_mean=np.zeros(len(ratios_columns), dtype = float)\n",
        "for i in range(len(ratios_columns)):\n",
        "  name=ratios_columns[i]\n",
        "  weight_mean[i]=df[numerators_columns[i]].sum()/df[denomintaor_columns[i]].sum()\n",
        "df_stats=df_stats.T\n",
        "df_stats['weight mean']=weight_mean\n",
        "print(df_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtD8wJRpBE6E"
      },
      "source": [
        "2022:\n",
        "\n",
        "\n",
        "*   pm = 0.104924\n",
        "*   ato = 0.738371\n",
        "\n",
        "\n",
        "\n",
        "Haciendo el mismo análisis con solo el año 2022 Podemos ver que la capacidad de hacer activos gananacias es casi la misma. Pero a comparación del registro históricon en el año 2022 el margen de ganancias está 3% por encima. **Es decir el año 2022 ha sido un buen años financieramente hablando para la industria manofacturera.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNoOSlN2BdCf"
      },
      "source": [
        "##1.2 Regresión lineal multiple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLaaHEOPCpQO"
      },
      "source": [
        "### 1.2.1 Calculo de variables para la regresión\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzAQjANCXpCE"
      },
      "source": [
        "#### Clasificación por tamaño\n",
        "Agregaremos etiquetas de tamaño a cada empresa. Las clasificaremos en pequeña mediana y grande de acuerdo al percentil en el que se encuentren. Vamos a hacer una partición en 3 partes iguales con los cuartiles 33% y 66%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbsOuB8YDoqt"
      },
      "outputs": [],
      "source": [
        "df=df_m.copy();\n",
        "# Calculate percentiles\n",
        "limits=[0.3333,0.6666]\n",
        "percentiles = df['mvalue'].quantile(limits)\n",
        "\n",
        "# Define function to categorize values\n",
        "def categorize_size(value):\n",
        "    if value <= percentiles[limits[0]]:\n",
        "        return 'small'\n",
        "    elif value <= percentiles[limits[1]]:\n",
        "        return 'medium'\n",
        "    else:\n",
        "        return 'big'\n",
        "\n",
        "# Apply the categorize_size function to create the \"size\" column\n",
        "df['size'] = df['mvalue'].apply(categorize_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjUeYr8uBGnr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5CxU4aUa1cf"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DE0YhrYJMCq"
      },
      "outputs": [],
      "source": [
        "# Create a histogram with colors based on 'size'\n",
        "sns.histplot(data=df, x='mvalue', bins=80, log_scale=(False, True), hue='size', multiple='stack')\n",
        "\n",
        "plt.xlabel('Market Value')\n",
        "plt.ylabel('Frequency (log scale)')\n",
        "plt.title('Logarithmic Histogram of Market Value by Size')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ_HrxJCJEXz"
      },
      "source": [
        "Comprobamos que tengan tamaños similares después de hacer el One-hot-encoding con size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BUdbheQBkyU"
      },
      "source": [
        "#### Dummie encoding por tamaño de la empresa\n",
        "\n",
        "Vamos a obtener columnas adicionales donde nos indica si es de tamaño chica, mediana o grande.\n",
        "\n",
        "IMPORTANTE: Por fines prácticos calculamos los 3 dummies, uno por cada tamaño. Pero en los siguientes pasos solo usaremos lo dummies de big y small ya que vamos a hacer el análisis de efecto indirecto tomando como grupo base aquellas empresas que son de tamaño mediano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrPWodwtHlu0"
      },
      "outputs": [],
      "source": [
        "#Dummie encoding\n",
        "df = pd.get_dummies(df, columns=['size'], prefix='size')\n",
        "df[['size_big','size_medium','size_small']].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opvnZ4sHxulu"
      },
      "source": [
        "#### Calculando otras variables\n",
        "\n",
        "*   Calculate operating earnings per share deflated by stock price: oepsp = (ebit / sharesoutstanding) / originalprice.\n",
        "*   Calculate earnings per share deflated by stock price: epsp = (netincome / sharesoutstanding) / originalprice\n",
        "*   Calculate book-to-market ratio: bmr = bookvalue / marketvalue\n",
        "\n",
        "**Tenemos que oepsp=  (ebit / sharesoutstanding) / originalprice = (ebit / (originalprice * sharesoutstanding)) = ebit / mvalue**\n",
        "\n",
        "**De igual manera epsp =  (netincome / sharesoutstanding) / originalprice = netincome / mvalue**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TRk2B7nxrFF"
      },
      "outputs": [],
      "source": [
        "df['oepsp']=np.where(df['mvalue']==0,np.NaN, df['ebit']/ df['mvalue'])\n",
        "df['epsp']=np.where(df['mvalue']==0,np.NaN, df['netincome']/ df['mvalue'])\n",
        "df['bmr']=np.where(df['mvalue']==0,np.NaN, df['bookvalue']/ df['mvalue'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWg3-6AtDCgB"
      },
      "source": [
        "Este dataset en un principio contenia la información de la industria manofacturera en todos los trimestres. Ahora hemos agregado los dummies por tamaño y otras variables extra. Vamos a guardar este dataset como df_regression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BVXb69kDIVf"
      },
      "outputs": [],
      "source": [
        "df_regression=df\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KWHec572koG"
      },
      "source": [
        "### Modelo de regresión para predecir el retorno anual\n",
        "**Variable dependiente:**\n",
        "\n",
        "*   Retorno anual ('f1ry')\n",
        "\n",
        "**Variables independientes**\n",
        "\n",
        "*   Size dummies ('size_big','size_small')\n",
        "*   Operating earnings per share deflated by stock price ('oepsp')\n",
        "*   Earnings per share deflated by stock price ('epsp')\n",
        "*   BookValue-MarketValue Ration ('bmr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh2Nbw05C12L"
      },
      "source": [
        "#### Filtro de solo las variables que vamos a utilizar para esta regresión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bakscpi6FDuZ"
      },
      "outputs": [],
      "source": [
        "df=df_regression.copy()\n",
        "analized=['size_big','size_small','pm','ato','oepsp','epsp','bmr','f1ry']\n",
        "df[analized]\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7WG2XfHFN2y"
      },
      "source": [
        "#### Versión 1 : Regresión (EXTRA)\n",
        "Antes de tratar las variables vamos a correr una primera versión de la regresión para ver cómo va evolucionando"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_Z-Z-zG3OoA"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "X = df[['size_big','size_small','pm','ato','oepsp','epsp','bmr']]\n",
        "# Add a constant term (intercept) to the features\n",
        "X = sm.add_constant(X)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "# Define your target variable (dependent variable)\n",
        "y = df[\"f1ry\"]\n",
        "# Create and fit the linear regression model\n",
        "model = sm.OLS(y, X, missing=\"drop\").fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seByPPP730_m"
      },
      "outputs": [],
      "source": [
        "# Calculate the VIF for each independent variable\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "# Print the VIF values\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF-mX43R34ZX"
      },
      "outputs": [],
      "source": [
        "# Get the model summary\n",
        "model_summary = model.summary()\n",
        "# Print the model summary\n",
        "print(model_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9MOFX3PFmDD"
      },
      "source": [
        "RESUMEN:\n",
        "*   Una R^2 de 0.15. Es un modelo malo.\n",
        "*   Detectamos alta colinealidad en algunas variables.\n",
        "*    Tenemos T values significativos en todas las variables a excepción de pm y ato.\n",
        "\n",
        "Ideas:\n",
        "*   Que sea un empresa grande es significativo para el aumento de la variable dependiente. Las empresas grandes tienen mayores retornos trimestrales proyectados a un año.\n",
        "*   Analogo, que sea una empresa pequeña es significativo para tener menores retornos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRFrXfjA715p"
      },
      "source": [
        "### 1.2.2 Winsorización\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG0U0ozG9Fsn"
      },
      "source": [
        "#### Obtenemos el dataset base para la regresión y filtramos las variables que vamos a utilizar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCf0LFMUHZNs"
      },
      "source": [
        "Estadistica descriptiva"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQyXLMV59Geb"
      },
      "outputs": [],
      "source": [
        "df=df_regression.copy()\n",
        "analized=['size_big','size_small','pm','ato','oepsp','epsp','bmr','f1ry']\n",
        "df=df[analized]\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylhuiKirMFRk"
      },
      "outputs": [],
      "source": [
        "# Create histograms\n",
        "var2plot=['pm','ato','oepsp','epsp','bmr']\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, column in enumerate(var2plot):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.hist(df[column], bins=20, color='skyblue', alpha=0.75)\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_QJwqbjqq47"
      },
      "source": [
        "#### Winsorización manual\n",
        "Vamos a aplicar una winsorización manual. Es decir vamos a personalizar el porcentaje que se va a extraer de cada variable. Con la estádistica descriptiva anterior vamos a buscar valores que mejoren el error estándar. Notese que tenemos medias no mayores a 100 en todos los casos y desciacipnes estándares que llegan hasta los 3000. veamos cómo podemos mejorar estas desviaciones con winsorización.\n",
        "\n",
        "**Guardamos el dataset winsorizado como df_winsorized**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eU_hXAp8Ylp"
      },
      "outputs": [],
      "source": [
        "df=df_regression.copy()\n",
        "analized=['size_big','size_small','pm','ato','oepsp','epsp','bmr','f1ry']\n",
        "df=df[analized]\n",
        "columns_winzorization=['pm','ato','oepsp','epsp','bmr']\n",
        "low_quartile=         [0.02, 0.01,  0.01,  0.01,  0.01]\n",
        "high_quartile=        [0.99, 0.99,  0.99,  0.99,  0.99]\n",
        "for i in range(len(columns_winzorization)):\n",
        "  percentile_1 = df[columns_winzorization[i]].quantile(low_quartile[i])\n",
        "  percentile_99 = df[columns_winzorization[i]].quantile(high_quartile[i])\n",
        "  df[columns_winzorization[i]]=df[columns_winzorization[i]].clip(lower=percentile_1, upper=percentile_99)\n",
        "\n",
        "df_winsorized=df\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXrD1TIcLboO"
      },
      "source": [
        "En este caso vemos que con la winsorización de 1%-99% funciona bastante bien. Hacer 2% en PM mejora std de 25 a 12."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHbbTaKBMYtZ"
      },
      "outputs": [],
      "source": [
        "# Create histograms\n",
        "var2plot=['pm','ato','oepsp','epsp','bmr']\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i, column in enumerate(var2plot):\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.hist(df[column], bins=20, color='skyblue', alpha=0.75)\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnJDP9Cn-Cfr"
      },
      "source": [
        "Si bien winsorizar 1%-99% No resolvió todos los problemas con datos extremos mejoró mucho la escala. A diferencia los histogramas sin winsorizar esta escala redujo significativamente el número de cifras de los valores extremos. Por ejemplo de esps de -3,000,000 a -2.5 o de -25,000 a -200.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_HXVEqhBYel"
      },
      "source": [
        "### 1.2.3 Multicolinealidad\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a-5aNplQWOp"
      },
      "source": [
        "#### Matriz de correlación y VIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJfJdU4Q7wU3"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df.corr()\n",
        "# Set up the heatmap figure\n",
        "plt.figure(figsize = (20, 10))\n",
        "# Create heatmap using seaborn\n",
        "sns.heatmap(correlation_matrix, annot = True, cmap = \"coolwarm\", center = 0)\n",
        "# Show the plot\n",
        "plt.title(\"Correlación de las empresas en la industria manofacturera\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaUr4BxmQi-k"
      },
      "source": [
        "Vemos que esps y oesps tienen un alto índice de correlación. Básicamente explican lo mismo en el modelo de regresión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FPbagpEC-rU"
      },
      "outputs": [],
      "source": [
        "X = df[['size_big','size_small','pm','ato','oepsp','epsp','bmr']]\n",
        "# Add a constant term (intercept) to the features\n",
        "X = sm.add_constant(X)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "# Calculate the VIF for each independent variable\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# Print the VIF values\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vno8d6-ADiTU"
      },
      "source": [
        "Cómo era de esperarse tenemos que oespsp y espsp tienen alta relación. Para mejorar el modelo vamos a eliminar una variable en este caso oespsp. Para eliminarla."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLvtlxqqblgT"
      },
      "outputs": [],
      "source": [
        "df_winsorized_multicol = df.drop([\"oepsp\"], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_fFkC3xf0CL"
      },
      "source": [
        "###1.2.4 Multiple regression model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrUN1RkgdOpf"
      },
      "source": [
        "#### Versión 2: Regresión después de winsoerizar y tratar multicolinealidad.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QM_n6cjJcIp9"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "df=df_winsorized_multicol.copy()\n",
        "#Solo las variables que nos importan\n",
        "selected=['size_big','size_small','pm','ato','epsp','bmr']\n",
        "X = df[selected]\n",
        "# Add a constant term (intercept) to the features\n",
        "X = sm.add_constant(X)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "# Define your target variable (dependent variable)\n",
        "y = df[\"f1ry\"]\n",
        "# Create and fit the linear regression model\n",
        "model = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "# Calculate the VIF for each independent variable\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "# Print the VIF values\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTLusGARd0Xl"
      },
      "outputs": [],
      "source": [
        "# Get the model summary\n",
        "model_summary = model.summary()\n",
        "# Print the model summary\n",
        "print(model_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef5gxcFheEIi"
      },
      "source": [
        "RESUMEN:\n",
        "*   Una R^2 de 0.25 mejor que el 0.15 que obtuvimos antes de winsorizar.\n",
        "*   Ya no ha alta colinealidad entre nuestrasa variables.\n",
        "*   En este caso TODAS nuestras variables tienen |t values| mayores que 2. TODAS NUESTRAS VARIABLES SON SIGNIFICATIVAS para explicar el modelo.\n",
        "\n",
        "Ideas:\n",
        "*   A expeción de pm, ningún intervalo del 95% de confianza contiene el 0. Son mayores o menores que 1. Por lo que podemos decir que existen ciertos factores que afectan para aumentar los retornos trimestrales el próximo año.\n",
        "\n",
        "Una empresa aumenta los retornos con evidencia estadistica si:\n",
        "1.   Es una empresa grande en lugar de una empresa mediana.\n",
        "2.   Aumenta su asset turn over ratio.\n",
        "3.   Aumenta su earnings per share deflated by stock price.\n",
        "\n",
        "Una empresa decrese los retornos con evidencia estadistica si:\n",
        "1.   Es una empresa pequeña en lugar de una empresa mediana.\n",
        "2.   Aumenta el ratio de valor de libro sobre valor de mercado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCQ-F1Ipiq9S"
      },
      "source": [
        "#### Versión 3: Regresión con winsorización, colinealidad tratada y variables de interacción\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBBrPDD9jiXa"
      },
      "source": [
        "Añadimos terminos de interacción\n",
        "Para este modelo agregamos la interacción de earnings per share deflated by stock price con el tamaño de la empresa. Queremos comprobar que la etiqueta por tamaño de la empresa y esta variable explican mejor el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bIzKtyNEFkT"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "df=df_winsorized_multicol.copy()\n",
        "#Añadimos variables de interacción\n",
        "df['epsp*big']=df['epsp']*df['size_big']\n",
        "df['epsp*small']=df['epsp']*df['size_small']\n",
        "#Seleccionamos las variables para el modelo\n",
        "selected=['size_big','size_small','pm','ato','epsp','epsp*big','epsp*small','bmr']\n",
        "X = df[selected]\n",
        "# Add a constant term (intercept) to the features\n",
        "X = sm.add_constant(X)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "# Define your target variable (dependent variable)\n",
        "y = df[\"f1ry\"]\n",
        "# Create and fit the linear regression model\n",
        "model = sm.OLS(y, X, missing=\"drop\").fit()\n",
        "# Calculate the VIF for each independent variable\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variable\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "# Print the VIF values\n",
        "print(vif_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLnhtKJ2EvLy"
      },
      "outputs": [],
      "source": [
        "# Get the model summary\n",
        "model_summary = model.summary()\n",
        "# Print the model summary\n",
        "print(model_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyCvgOx8kLBc"
      },
      "source": [
        "**INTERPRETEMOS ESTE MODELO CON VARIABLESD DE INTERACCION**\n",
        "RESUMEN:\n",
        "*   Una R^2 de 0.253 casi igual que 0.252 que obtuvimos antes, no presenta mejora significativa al tratar de predecir el modelo. Solo explica el 25% de la variabilidad del modelo.\n",
        "*   Hay alta colinealidad entre la variable de interacción de empresa pequeña con su variable directa esps. Esto significa que esps explica la mismo en una empresa mediana. Pero la interpretación es distinta con la variables indirectas.\n",
        "\n",
        "*   En este caso TODAS nuestras variables tienen |t values| mayores que 2. TODAS NUESTRAS VARIABLES SON SIGNIFICATIVAS para explicar el modelo.\n",
        "\n",
        "Ecuación de regresión por cada tamaño de empresa:\n",
        "*   Empresa mediana:    \n",
        "\n",
        "**f1ry = (0.081     + 0.54*epsp -0.16*bmr + 0.04*ato + 0.001*pm)**\n",
        "*   Empresa pequeña:\n",
        "\n",
        "f1ry = (0.081-0.059) + (0.54+0.13)*epsp -0.16*bmr + 0.04*ato + 0.001*pm\n",
        "\n",
        "**f1ry = (0.022     + 0.67*epsp -0.16*bmr + 0.04*ato + 0.001*pm)**\n",
        "*   Empresa grande:\n",
        "\n",
        "f1ry = (0.081+0.03)  + (0.54-0.13)4*epsp -0.16*bmr + 0.04*ato + 0.001*pm\n",
        "     \n",
        "**f1ry = (0.111     + 0.41*epsp -0.16*bmr + 0.04*ato + 0.001*pm)**\n",
        "\n",
        "\n",
        "\n",
        "Sobre las variables de interacción:\n",
        "* Podemos decir que la variable de interacción de una empresa pequeña si es estadisticamente significativa y hace referencia a que, a comparación de la empresa mediana, una empresa pequeña tiene mayor earnings per share deflated by stock price. Dado que epsp es la variable con mayor t value, mayor coeficiente y su intervalo de confianza es positivo podemos afirmar que: **Una empresa pequeña tiene más posibilidad de tener un mayor crecimiento en el retorno trimestral proyectado a un año a comparación de una mediana o una grande de acuerdo a este modelo.**\n",
        "* Por otra parte la variable de interacción de la empresa grande no es, ni estadisticamente significativa ni indica un claro comportamiento de epsp respecto a la empresa mediana.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl_TUXQDLn2a"
      },
      "source": [
        "#### Versión 4: Regresión con winsorización, trada multicolinealidad y variables de interaccion esps con datos del último año.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_winsorized_multicol.columns"
      ],
      "metadata": {
        "id": "4HPQwy3U-8CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE7mv-UkM7hM"
      },
      "outputs": [],
      "source": [
        "df=df_regression.copy()\n",
        "#Filtro de años fiscal\n",
        "df=df[df['qy']=='2022']\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89HHl7TaLydr"
      },
      "outputs": [],
      "source": [
        "df=df_regression.copy()\n",
        "#Filtro de años fiscal\n",
        "df=df[df['qy']=='2022']\n",
        "\n",
        "#Añadimos variables de interacción\n",
        "df['epsp*big']=df['epsp']*df['size_big']\n",
        "df['epsp*small']=df['epsp']*df['size_small']\n",
        "#Wizorisation\n",
        "analized=['size_big','size_small','pm','ato','epsp','epsp*big','epsp*small','bmr','f1ry']\n",
        "df=df[analized]\n",
        "columns_winzorization=['pm','ato','epsp','bmr']\n",
        "low_quartile=         [0.02, 0.01,  0.01,  0.01]\n",
        "high_quartile=        [0.99, 0.99,  0.99,  0.99]\n",
        "for i in range(len(columns_winzorization)):\n",
        "  percentile_1 = df[columns_winzorization[i]].quantile(low_quartile[i])\n",
        "  percentile_99 = df[columns_winzorization[i]].quantile(high_quartile[i])\n",
        "  df[columns_winzorization[i]]=df[columns_winzorization[i]].clip(lower=percentile_1, upper=percentile_99)\n",
        "df.describe()\n",
        "##Guardemos el dataset en df_regression_2022\n",
        "df_regression_2022=df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pySkTUnYPHYq"
      },
      "outputs": [],
      "source": [
        "selected=['size_big','size_small','pm','ato','epsp','epsp*big','epsp*small','bmr']\n",
        "X = df[selected]\n",
        "# Add a constant term (intercept) to the features\n",
        "X = sm.add_constant(X)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "# Define your target variable (dependent variable)\n",
        "y = df[\"f1ry\"]\n",
        "# Create and fit the linear regression model\n",
        "model = sm.OLS(y, X, missing=\"drop\").fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1T8Uap2MLyiR"
      },
      "outputs": [],
      "source": [
        "# Get the model summary\n",
        "model_summary = model.summary()\n",
        "# Print the model summary\n",
        "print(model_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEkpTOkAR4Q_"
      },
      "source": [
        "RESUMEN:\n",
        "*   Una R^2 de 0.45 ha mejorado por mucho los modelos anteriores.\n",
        "*   El tmaño de las empresas y el epsp son variables que explican con mayor confianza el modelo.\n",
        "\n",
        "Ideas:\n",
        "*   Con argumento estadistico una empresa pequeña gana menos que una empresa mediana y una grande gana más que una mediana en las mismas condiciones. Esto debido a que la constante b es menor, cuando una empresa es pequeña y mayor cuando es grande.\n",
        "*   Así como en los modelos anteriores a mayor crecimiento de epsp más grandes son los retornos trimestrales en un año futuro.\n",
        "\n",
        "Hasta el momento este fue el mejor modelo, hicimos limpieza de valores extremos,, agregamos una variable categórica de acuerdo al tamaño,  eliminamos multicolinealidad y añadimos una variable de interacción con nuestra variable con mayor significancia en el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghWzxADkf7BW"
      },
      "source": [
        "### 1.2.5 Regression Diagnosis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUlfiL5HLyr6"
      },
      "outputs": [],
      "source": [
        "influence = model.get_influence()\n",
        "# Get the summary frame\n",
        "summary_frame = influence.summary_frame()\n",
        "# Display the summary frame\n",
        "print(summary_frame[['cooks_d','standard_resid','hat_diag','student_resid']])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Coeficientes con algebra matricial\n"
      ],
      "metadata": {
        "id": "KbQ-sTPxjbPA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvJe5bpujY13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hat Matrix con algebra matricial"
      ],
      "metadata": {
        "id": "UnDRb8oqjmjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIKZfataf0lb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Leverage observations\n"
      ],
      "metadata": {
        "id": "iNn63PiLjxN_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhZfaHitfy-z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Outliers usando studentized residuals"
      ],
      "metadata": {
        "id": "ipykl_Idj1ja"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evLINX2FuspT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDb5xr-qvUo-"
      },
      "source": [
        "####  outliers usando Cook’s distance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crbj3UHpussk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uun4s1zLvZ1u"
      },
      "source": [
        "Using matrix algebra calculate the Hat Matrix\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa9coM43vZ9H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh5-yGFBvaEw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLrEf44XvaNO"
      },
      "outputs": [],
      "source": [
        "\n",
        "#OLSInfluence(model).summary_frame()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "dShKeI48nmXw"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOxXrSA/TfgOIiqAVNNX5bn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}